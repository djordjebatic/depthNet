{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as numpy\n",
    "from dataloader import FlyingThingsLoader as FLY\n",
    "from model.basic import DispNetSimple\n",
    "from utils import dataset_loader\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import time\n",
    "from model.loss import multiscaleloss, AverageMeter\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda:1\")\n",
    "MAX_SUMMARY_IMAGES = 4\n",
    "LR = 3e-4\n",
    "EPOCHS = 300\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 8\n",
    "LOSS_WEIGHTS = [[0.32, 0.16, 0.08, 0.04, 0.02, 0.01, 0.005]]\n",
    "MODEL_PTH = 'saved_models/'\n",
    "\n",
    "assert MAX_SUMMARY_IMAGES <= BATCH_SIZE\n",
    "\n",
    "torch.manual_seed(1)\n",
    "torch.cuda.manual_seed(1)\n",
    "\n",
    "\n",
    "def make_data_loaders(root = 'FlyingThings3D_subset'):\n",
    "    'Loads the train and val datasets'\n",
    "    left_imgs_train, right_imgs_train, left_disps_train, left_imgs_val, right_imgs_val, left_disps_val = dataset_loader.load_data(root)\n",
    "\n",
    "    print(len(left_disps_train), len(left_imgs_train))\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        FLY.FlyingThingsDataloader(left_imgs_train[:12000], right_imgs_train[:12000], left_disps_train[:12000], True),\n",
    "        batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, pin_memory=True, drop_last=False\n",
    "    )\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        FLY.FlyingThingsDataloader(left_imgs_val, right_imgs_val, left_disps_val, False),\n",
    "        batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, pin_memory=True, drop_last=False\n",
    "    )\n",
    "\n",
    "    print('Data loaded.')\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def model_init(dual_gpu=False):\n",
    "    model = DispNetSimple().to(DEVICE)\n",
    "    if dual_gpu:\n",
    "        model = nn.DataParallel(model)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "    print('Model initialized.')\n",
    "    print('Number of model parameters:\\t{}'.format(sum([p.data.nelement() for p in model.parameters()])))\n",
    "    return model, optimizer\n",
    "\n",
    "\n",
    "def calculate_loss(output, disp_true, weights = None):\n",
    "    pr1, pr2, pr3, pr4, pr5, pr6 = output\n",
    "\n",
    "    # predict flow upsampling\n",
    "    out_size = pr1.shape[-2:]\n",
    "    out1 = pr1\n",
    "    out2 = F.interpolate(pr2, out_size, mode='bilinear')\n",
    "    out3 = F.interpolate(pr3, out_size, mode='bilinear')\n",
    "    out4 = F.interpolate(pr4, out_size, mode='bilinear')\n",
    "    out5 = F.interpolate(pr5, out_size, mode='bilinear')\n",
    "    out6 = F.interpolate(pr6, out_size, mode='bilinear')\n",
    "\n",
    "    # squeeze\n",
    "    out1 = torch.squeeze(out1, 1)\n",
    "    out2 = torch.squeeze(out2, 1)\n",
    "    out3 = torch.squeeze(out3, 1)\n",
    "    out4 = torch.squeeze(out4, 1)\n",
    "    out5 = torch.squeeze(out5, 1)\n",
    "    out6 = torch.squeeze(out6, 1)\n",
    "\n",
    "    # weights\n",
    "    if weights is None:\n",
    "        weights = [0.0025, 0.005, 0.01, 0.02, 0.08, 0.32]\n",
    "\n",
    "    outs = (out6, out5, out4, out3, out2, out1)\n",
    "    loss = 0\n",
    "    for w, o in zip(weights, outs):\n",
    "        loss_delta = w * F.smooth_l1_loss(o, disp_true, size_average=True)\n",
    "        loss += loss_delta\n",
    "\n",
    "    # loss = F.smooth_l1_loss(output1[mask], disp_true[mask], size_average=True)\n",
    "\n",
    "    return loss\n",
    "\n",
    "def train_sample(model, optimizer, train_loader, val_loader, root = 'FlyingThings3D_subset'):\n",
    "\n",
    "    total_train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "\n",
    "    # TODO Initialize the Tensorboard summary. Logs will end up in runs directory\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    print('Training loop started.')\n",
    "\n",
    "    for epoch in range(1, EPOCHS):\n",
    "        for batch_idx, (imgL, imgR, dispL) in enumerate(train_loader):\n",
    "\n",
    "            #criterion = multiscaleloss(7, 1, LOSS_WEIGHTS[batch_idx], loss='L1', sparse=False)\n",
    "\n",
    "            imgL = Variable(torch.FloatTensor(imgL).to(DEVICE), requires_grad=False)\n",
    "            imgR = Variable(torch.FloatTensor(imgR).to(DEVICE), requires_grad=False)\n",
    "            disp_true = Variable(torch.FloatTensor(dispL).to(DEVICE), requires_grad=False)\n",
    "            input_cat = Variable(torch.cat((imgL, imgR), 1), requires_grad=False)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input_cat)\n",
    "\n",
    "            loss = calculate_loss(output, disp_true)\n",
    "\n",
    "            '''\n",
    "                loss = criterion(output, dispL)\n",
    "                if type(loss) is list or type(loss) is tuple:\n",
    "                    loss = torch.sum(loss)\n",
    "\n",
    "                losses.update(loss.data.item(), disp_true.size(0))\n",
    "            '''\n",
    "\n",
    "            total_train_loss += loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        torch.save(model.state_dict(), MODEL_PTH + str(epoch) + '_dispnet.pth')\n",
    "        total_train_loss += loss\n",
    "        writer.add_scalar('loss/train', loss, epoch)\n",
    "        print('Epoch {} loss: {:.3f} Time elapsed: {:.3f}'.format(epoch, loss, time.time() - start))\n",
    "\n",
    "    print('Total loss is: {:.3f}'.format(total_train_loss/EPOCHS))\n",
    "    del model, imgL, imgR, disp_true\n",
    "    print('Total time elapsed: {:.3f}'.format(time.time() - start))\n",
    "\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21818 21818\n",
      "Data loaded.\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader = make_data_loaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class WrappedModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WrappedModel, self).__init__()\n",
    "        self.module = DispNetSimple().to(DEVICE) # that I actually define.\n",
    "    def forward(self, x):\n",
    "        return self.module(x)\n",
    "\n",
    "# then I load the weights I save from previous code:\n",
    "model = WrappedModel()\n",
    "state_dict = torch.load(\"saved_models/46_dispnet.pth\")\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_sample(model, optimizer, train_loader, val_loader, root = 'FlyingThings3D_subset'):\n",
    "\n",
    "    total_train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "\n",
    "    # TODO Initialize the Tensorboard summary. Logs will end up in runs directory\n",
    "    writer = SummaryWriter()\n",
    "\n",
    "    print('Training loop started.')\n",
    "\n",
    "    for epoch in range(1, EPOCHS):\n",
    "        for batch_idx, (imgL, imgR, dispL) in enumerate(train_loader):\n",
    "\n",
    "            #criterion = multiscaleloss(7, 1, LOSS_WEIGHTS[batch_idx], loss='L1', sparse=False)\n",
    "\n",
    "            imgL = Variable(torch.FloatTensor(imgL).to(DEVICE), requires_grad=False)\n",
    "            imgR = Variable(torch.FloatTensor(imgR).to(DEVICE), requires_grad=False)\n",
    "            disp_true = Variable(torch.FloatTensor(dispL).to(DEVICE), requires_grad=False)\n",
    "            input_cat = Variable(torch.cat((imgL, imgR), 1), requires_grad=False)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            output = model(input_cat)\n",
    "\n",
    "            loss = calculate_loss(output, disp_true)\n",
    "\n",
    "            '''\n",
    "                loss = criterion(output, dispL)\n",
    "                if type(loss) is list or type(loss) is tuple:\n",
    "                    loss = torch.sum(loss)\n",
    "\n",
    "                losses.update(loss.data.item(), disp_true.size(0))\n",
    "            '''\n",
    "\n",
    "            total_train_loss += loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        torch.save(model.state_dict(), MODEL_PTH + str(epoch) + '_dispnet.pth')\n",
    "        total_train_loss += loss\n",
    "        writer.add_scalar('loss/train', loss, epoch)\n",
    "        print('Epoch {} loss: {:.3f} Time elapsed: {:.3f}'.format(epoch, loss, time.time() - start))\n",
    "\n",
    "    print('Total loss is: {:.3f}'.format(total_train_loss/EPOCHS))\n",
    "    del model, imgL, imgR, disp_true\n",
    "    print('Total time elapsed: {:.3f}'.format(time.time() - start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:psiml_gpu]",
   "language": "python",
   "name": "conda-env-psiml_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
